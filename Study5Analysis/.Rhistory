knitr::opts_chunk$set(echo = TRUE)
library(pwr)
library(tidyverse)
library(splitstackshape)
library(stringr)
library(data.table)
library(dplyr)
library(plyr)
library(tidyr)
library(gridExtra)
library(lme4)
library(lmerTest)
library(afex)
library(effects)
library(ggplot2)
library(ggthemes)
library(report)
library(janitor)
library(stringr)
pwr.t.test(n = 30, sig.level = 0.05, d = 0.814646, type = "two.sample")
# Plot sample size curves for detecting correlations of
# various sizes.
library(pwr)
# range of correlations
r <- seq(.1,.5,.01)
nr <- length(r)
# power values
p <- seq(.4,.9,.1)
np <- length(p)
# obtain sample sizes
samsize <- array(numeric(nr*np), dim=c(nr,np))
for (i in 1:np){
for (j in 1:nr){
result <- pwr.r.test(n = NULL, r = r[j],
sig.level = .05, power = p[i],
alternative = "two.sided")
samsize[j,i] <- ceiling(result$n)
}
}
# set up graph
xrange <- range(r)
yrange <- round(range(samsize))
colors <- rainbow(length(p))
plot(xrange, yrange, type="n",
xlab="Correlation Coefficient (r)",
ylab="Sample Size (n)" )
# add power curves
for (i in 1:np){
lines(r, samsize[,i], type="l", lwd=2, col=colors[i])
}
# add annotation (grid lines, title, legend)
abline(v=0, h=seq(0,yrange[2],50), lty=2, col="grey89")
abline(h=0, v=seq(xrange[1],xrange[2],.02), lty=2,
col="grey89")
title("Sample Size Estimation for Correlation Studies\n
Sig=0.05 (Two-tailed)")
legend("topright", title="Power",
as.character(p),
fill=colors)
dataFolder = "C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 5/Study5Data/WHN/"
file_list <- list.files(path = dataFolder, pattern = "..csv$", all.files = TRUE, full.names = TRUE, recursive = TRUE)
library(plyr)
RawWHNDataset <- data.frame()
#loop through all the fills, create a temporary container, remove the first, second and last rows and then add 1 to the trials counter. Then bind it to the dataset
for (file in file_list){
tempData <- read.csv(file, header = T)
RawWHNDataset <- rbind.fill(RawWHNDataset, tempData)
}
library(dplyr)
#Sort dataset for useful columns
SortedWHNDataset <- RawWHNDataset  %>%
dplyr::select(participant,date, image_file,Correct,trials_3.thisTrialN, conf_slider.response, conf_slider.rt, Attention_slider.response, trialResp.keys, trialResp.corr, trialResp.rt, preTrial_text.started)
SortedWHNDataset$Attention_slider.response <- as.numeric(SortedWHNDataset$Attention_slider.response)
SortedWHNDataset$participant <- as.factor(SortedWHNDataset$participant)
SortedWHNDataset$image_file <- as.factor(SortedWHNDataset$image_file)
SortedWHNDataset <- SortedWHNDataset[complete.cases(SortedWHNDataset$trialResp.corr), ]
#Read in counterbalancing
Counterbalancing <- read.csv("C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 5/Study5CounterbalancingCSV.csv", header = T)
colnames(Counterbalancing) <- c("participant", "First", "Second","Third","Fourth")
OrderWHNDataset <- left_join(SortedWHNDataset, Counterbalancing, by = 'participant')
OrderWHNDataset$Block
OrderWHNDataset$Block <-  if_else(OrderWHNDataset$trials_3.thisTrialN >= 30,OrderWHNDataset$Fourth,
if_else(OrderWHNDataset$trials_3.thisTrialN >= 20,OrderWHNDataset$Third,
if_else(OrderWHNDataset$trials_3.thisTrialN >= 10,OrderWHNDataset$Second,
OrderWHNDataset$First)))
OrderWHNDataset$trialResp.rt <-stringr::str_remove_all(OrderWHNDataset$trialResp.rt,"[\\[\\]]")
OrderWHNDataset$trialResp.rt <- as.numeric(OrderWHNDataset$trialResp.rt)
OrderWHNDataset$image_file <- str_sub(OrderWHNDataset$image_file, end = -5)
WHNDataset <- OrderWHNDataset
#Read in the data
DemogDataRaw <- read.csv("C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 5/Study5Data/Qualtrics/Demogs/TGStudy5Demogs.csv") %>%
select(starts_with('Q'))
#Change the first row into column headers
DemogDataOrg <- row_to_names(DemogDataRaw, row_number = 1)
DemogDataOrg <- DemogDataOrg %>%
subset(DemogDataOrg$`What is your participant ID?
(First two letters of your first name, the month  number of your birthday and the last two letters of your mothers maiden name - eg TH03ON)` != "DO12TA")
#Remove consent form columns
DemogDataOrg <- DemogDataOrg %>%
rename(c(`What is your age?` = "Age")) %>%
rename(c(`Which gender do you identify with?` = "Gender")) %>%
rename(c(`Do you have a UK driving license?` = "UKLicense")) %>%
rename(c(`Which country did you get your driving license in?` = "CountryLicense")) %>%
rename(c(`How many years driving experience do you have, either from when you passed your driving test or when you started driving regularly? (years / months)` = "YearsExp")) %>%
rename(c(`How many years driving experience do you have in the UK (years, months)` = "UKYearsExp")) %>%
rename(c(`How many years driving experience do you have driving around the West End of Glasgow? (years, months)` = "GlasgowYearsExp")) %>%
rename(c(`Approximately how many hours do you play video games for in an average week?` = "VideoGamesTime")) %>%
rename(c(`Do you have any history of motion sickness? - Selected Choice` = "MotionSickness")) %>%
rename(c(`Do you have any history of motion sickness? - Other (Please describe) - Text` = "MotionSicknessText"))
DemogDataOrg$Age = as.numeric(DemogDataOrg$Age)
DemogDataOrg$VideoGamesTime = as.numeric(DemogDataOrg$VideoGamesTime)
DemogDataOrg$YearsExp = as.numeric(DemogDataOrg$YearsExp)
DemogDataOrg$UKYearsExp = as.numeric(DemogDataOrg$UKYearsExp)
DemogDataOrg$GlasgowYearsExp = as.numeric(DemogDataOrg$GlasgowYearsExp)
DemogDataOrg <- DemogDataOrg[!is.na(DemogDataOrg$Age),]
#table(DemogDataOrg$`How familiar are you with augmented reality (AR) prior to this experiment?`)
#table(DemogDataOrg$`How familiar are you with virtual reality (VR) prior to this experiment?`)
DemogSummaryTotal <- DemogDataOrg
DemogSummaryTotal <- DemogSummaryTotal %>%
summarise(
AgeMean = mean(Age),
AgeSD = sd(Age, na.rm = T),
Male = sum(Gender == 'Male'),
Female = sum(Gender == "Female"),
YearsExp = mean(YearsExp),
YearsExpsd = sd(YearsExp, na.rm = T),
UKLicense = sum(UKLicense == 'Yes'),
UKExp = mean(UKYearsExp, na.rm = T),
UKExpmin = min(UKYearsExp, na.rm = T),
UKExpmax = max(UKYearsExp, na.rm = T),
UKEXPsd = sd(UKYearsExp, na.rm = T),
GlasgowExp = mean(GlasgowYearsExp, na.rm = T),
GlasgowExpmin = min(GlasgowYearsExp, na.rm = T),
GlasgowExpmax = max(GlasgowYearsExp, na.rm = T),
GlasgowExpsd = sd(GlasgowYearsExp, na.rm = T),
meanVG = mean(VideoGamesTime, na.rm = T),
meanExp = mean(YearsExp, na.rm = T),
minExp = min(YearsExp, na.rm = T),
maxExp = max(YearsExp, na.rm = T),
sdExp = sd(YearsExp, na.rm = T)
)
DBQ <- DemogDataOrg %>%
select(11: 34)
library(dplyr)
DBQ <- DBQ %>% mutate_all(list(~substr(., 1, 1)))
IDs <- as.data.frame(WHNDataset$participant)
IDs <- IDs[!duplicated(IDs), ]
IDs <- as.data.frame(IDs)
DBQItems <- cols <- names(DBQ)
DBQ[DBQItems] <- lapply(DBQ[DBQItems], as.numeric)
DBQ$Errors <- 0
DBQ$Lapses <- 0
DBQ$Violations <- 0
DBQ$participant <- IDs
ClipSummary <- WHNDataset %>%
group_by(image_file) %>%
summarise(n = n(),
WHN = sum(trialResp.corr),
sdWHN = sd(trialResp.corr))
WHNDataset$participant <- as.factor(WHNDataset$participant)
WHNDataset$image_file[WHNDataset$image_file == "Slide1"] <- "Slide01"
WHNDataset$image_file[WHNDataset$image_file == "Slide2"] <- "Slide02"
WHNDataset$image_file[WHNDataset$image_file == "Slide3"] <- "Slide03"
WHNDataset$image_file[WHNDataset$image_file == "Slide4"] <- "Slide04"
WHNDataset$image_file[WHNDataset$image_file == "Slide5"] <- "Slide05"
WHNDataset$image_file[WHNDataset$image_file == "Slide6"] <- "Slide06"
WHNDataset$image_file[WHNDataset$image_file == "Slide7"] <- "Slide07"
WHNDataset$image_file[WHNDataset$image_file == "Slide8"] <- "Slide08"
WHNDataset$image_file[WHNDataset$image_file == "Slide9"] <- "Slide09"
#WHNDataset$Block <- factor(WHNDataset$Block, levels = c("0 Control", "1 Visual",  "2 Social", "3 NDRT"))
NoPpts <- n_distinct(WHNDataset$participant)
PPTWHNData <- WHNDataset[!duplicated(WHNDataset$participant), ]
#detach(package:plyr)
WHNSummary <- WHNDataset %>%
group_by(Block) %>%
summarise(WHN = sum(trialResp.corr / NoPpts) ,
WHNPercent = sum((trialResp.corr / NoPpts) /10) * 100,
sdWHN = sd(trialResp.corr),
seWHN = (sd(trialResp.corr))/ sqrt(NoPpts),
meanConf = mean(conf_slider.response, na.rm = T),
sdConf = sd(conf_slider.response),
seConf = (sd(conf_slider.response))/ sqrt(NoPpts),
meanAttention = mean(Attention_slider.response, na.rm = T),
sdAttention = sd(Attention_slider.response, na.rm=T),
seAttention = (sd(Attention_slider.response, na.rm=T))/ sqrt(NoPpts),
trialRespmean = mean(trialResp.rt, na.rm=T),
trialRespSD = sd(trialResp.rt, na.rm=T)
)
write.csv(WHNDataset, "C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 5/data/S5WHN.csv", row.names=FALSE)
ClipSummary <- WHNDataset %>%
group_by(image_file) %>%
summarise(n = n(),
WHN = sum(trialResp.corr),
sdWHN = sd(trialResp.corr))
View(WHNSummary)
knitr::opts_chunk$set(echo = TRUE)
library(pwr)
library(tidyverse)
library(splitstackshape)
library(stringr)
library(data.table)
library(dplyr)
library(tidyr)
library(gridExtra)
library(lme4)
library(lmerTest)
library(afex)
library(effects)
library(ggplot2)
library(ggthemes)
library(report)
library(janitor)
library(stringr)
pwr.t.test(n = 30, sig.level = 0.05, d = 0.814646, type = "two.sample")
# Plot sample size curves for detecting correlations of
# various sizes.
library(pwr)
# range of correlations
r <- seq(.1,.5,.01)
nr <- length(r)
# power values
p <- seq(.4,.9,.1)
np <- length(p)
# obtain sample sizes
samsize <- array(numeric(nr*np), dim=c(nr,np))
for (i in 1:np){
for (j in 1:nr){
result <- pwr.r.test(n = NULL, r = r[j],
sig.level = .05, power = p[i],
alternative = "two.sided")
samsize[j,i] <- ceiling(result$n)
}
}
# set up graph
xrange <- range(r)
yrange <- round(range(samsize))
colors <- rainbow(length(p))
plot(xrange, yrange, type="n",
xlab="Correlation Coefficient (r)",
ylab="Sample Size (n)" )
# add power curves
for (i in 1:np){
lines(r, samsize[,i], type="l", lwd=2, col=colors[i])
}
# add annotation (grid lines, title, legend)
abline(v=0, h=seq(0,yrange[2],50), lty=2, col="grey89")
abline(h=0, v=seq(xrange[1],xrange[2],.02), lty=2,
col="grey89")
title("Sample Size Estimation for Correlation Studies\n
Sig=0.05 (Two-tailed)")
legend("topright", title="Power",
as.character(p),
fill=colors)
dataFolder = "C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 5/Study5Data/WHN/"
file_list <- list.files(path = dataFolder, pattern = "..csv$", all.files = TRUE, full.names = TRUE, recursive = TRUE)
library(plyr)
RawWHNDataset <- data.frame()
#loop through all the fills, create a temporary container, remove the first, second and last rows and then add 1 to the trials counter. Then bind it to the dataset
for (file in file_list){
tempData <- read.csv(file, header = T)
RawWHNDataset <- rbind.fill(RawWHNDataset, tempData)
}
library(dplyr)
#Sort dataset for useful columns
SortedWHNDataset <- RawWHNDataset  %>%
dplyr::select(participant,date, image_file,Correct,trials_3.thisTrialN, conf_slider.response, conf_slider.rt, Attention_slider.response, trialResp.keys, trialResp.corr, trialResp.rt, preTrial_text.started)
SortedWHNDataset$Attention_slider.response <- as.numeric(SortedWHNDataset$Attention_slider.response)
SortedWHNDataset$participant <- as.factor(SortedWHNDataset$participant)
SortedWHNDataset$image_file <- as.factor(SortedWHNDataset$image_file)
SortedWHNDataset <- SortedWHNDataset[complete.cases(SortedWHNDataset$trialResp.corr), ]
#Read in counterbalancing
Counterbalancing <- read.csv("C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 5/Study5CounterbalancingCSV.csv", header = T)
colnames(Counterbalancing) <- c("participant", "First", "Second","Third","Fourth")
OrderWHNDataset <- left_join(SortedWHNDataset, Counterbalancing, by = 'participant')
OrderWHNDataset$Block
OrderWHNDataset$Block <-  if_else(OrderWHNDataset$trials_3.thisTrialN >= 30,OrderWHNDataset$Fourth,
if_else(OrderWHNDataset$trials_3.thisTrialN >= 20,OrderWHNDataset$Third,
if_else(OrderWHNDataset$trials_3.thisTrialN >= 10,OrderWHNDataset$Second,
OrderWHNDataset$First)))
OrderWHNDataset$trialResp.rt <-stringr::str_remove_all(OrderWHNDataset$trialResp.rt,"[\\[\\]]")
OrderWHNDataset$trialResp.rt <- as.numeric(OrderWHNDataset$trialResp.rt)
OrderWHNDataset$image_file <- str_sub(OrderWHNDataset$image_file, end = -5)
WHNDataset <- OrderWHNDataset
#Read in the data
DemogDataRaw <- read.csv("C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 5/Study5Data/Qualtrics/Demogs/TGStudy5Demogs.csv") %>%
select(starts_with('Q'))
#Change the first row into column headers
DemogDataOrg <- row_to_names(DemogDataRaw, row_number = 1)
DemogDataOrg <- DemogDataOrg %>%
subset(DemogDataOrg$`What is your participant ID?
(First two letters of your first name, the month  number of your birthday and the last two letters of your mothers maiden name - eg TH03ON)` != "DO12TA")
#Remove consent form columns
DemogDataOrg <- DemogDataOrg %>%
rename(c(`What is your age?` = "Age")) %>%
rename(c(`Which gender do you identify with?` = "Gender")) %>%
rename(c(`Do you have a UK driving license?` = "UKLicense")) %>%
rename(c(`Which country did you get your driving license in?` = "CountryLicense")) %>%
rename(c(`How many years driving experience do you have, either from when you passed your driving test or when you started driving regularly? (years / months)` = "YearsExp")) %>%
rename(c(`How many years driving experience do you have in the UK (years, months)` = "UKYearsExp")) %>%
rename(c(`How many years driving experience do you have driving around the West End of Glasgow? (years, months)` = "GlasgowYearsExp")) %>%
rename(c(`Approximately how many hours do you play video games for in an average week?` = "VideoGamesTime")) %>%
rename(c(`Do you have any history of motion sickness? - Selected Choice` = "MotionSickness")) %>%
rename(c(`Do you have any history of motion sickness? - Other (Please describe) - Text` = "MotionSicknessText"))
DemogDataOrg$Age = as.numeric(DemogDataOrg$Age)
DemogDataOrg$VideoGamesTime = as.numeric(DemogDataOrg$VideoGamesTime)
DemogDataOrg$YearsExp = as.numeric(DemogDataOrg$YearsExp)
DemogDataOrg$UKYearsExp = as.numeric(DemogDataOrg$UKYearsExp)
DemogDataOrg$GlasgowYearsExp = as.numeric(DemogDataOrg$GlasgowYearsExp)
DemogDataOrg <- DemogDataOrg[!is.na(DemogDataOrg$Age),]
#table(DemogDataOrg$`How familiar are you with augmented reality (AR) prior to this experiment?`)
#table(DemogDataOrg$`How familiar are you with virtual reality (VR) prior to this experiment?`)
DemogSummaryTotal <- DemogDataOrg
DemogSummaryTotal <- DemogSummaryTotal %>%
summarise(
AgeMean = mean(Age),
AgeSD = sd(Age, na.rm = T),
Male = sum(Gender == 'Male'),
Female = sum(Gender == "Female"),
YearsExp = mean(YearsExp),
YearsExpsd = sd(YearsExp, na.rm = T),
UKLicense = sum(UKLicense == 'Yes'),
UKExp = mean(UKYearsExp, na.rm = T),
UKExpmin = min(UKYearsExp, na.rm = T),
UKExpmax = max(UKYearsExp, na.rm = T),
UKEXPsd = sd(UKYearsExp, na.rm = T),
GlasgowExp = mean(GlasgowYearsExp, na.rm = T),
GlasgowExpmin = min(GlasgowYearsExp, na.rm = T),
GlasgowExpmax = max(GlasgowYearsExp, na.rm = T),
GlasgowExpsd = sd(GlasgowYearsExp, na.rm = T),
meanVG = mean(VideoGamesTime, na.rm = T),
meanExp = mean(YearsExp, na.rm = T),
minExp = min(YearsExp, na.rm = T),
maxExp = max(YearsExp, na.rm = T),
sdExp = sd(YearsExp, na.rm = T)
)
DBQ <- DemogDataOrg %>%
select(11: 34)
library(dplyr)
DBQ <- DBQ %>% mutate_all(list(~substr(., 1, 1)))
IDs <- as.data.frame(WHNDataset$participant)
IDs <- IDs[!duplicated(IDs), ]
IDs <- as.data.frame(IDs)
DBQItems <- cols <- names(DBQ)
DBQ[DBQItems] <- lapply(DBQ[DBQItems], as.numeric)
DBQ$Errors <- 0
DBQ$Lapses <- 0
DBQ$Violations <- 0
DBQ$participant <- IDs
WHNDataset$participant <- as.factor(WHNDataset$participant)
WHNDataset$image_file[WHNDataset$image_file == "Slide1"] <- "Slide01"
WHNDataset$image_file[WHNDataset$image_file == "Slide2"] <- "Slide02"
WHNDataset$image_file[WHNDataset$image_file == "Slide3"] <- "Slide03"
WHNDataset$image_file[WHNDataset$image_file == "Slide4"] <- "Slide04"
WHNDataset$image_file[WHNDataset$image_file == "Slide5"] <- "Slide05"
WHNDataset$image_file[WHNDataset$image_file == "Slide6"] <- "Slide06"
WHNDataset$image_file[WHNDataset$image_file == "Slide7"] <- "Slide07"
WHNDataset$image_file[WHNDataset$image_file == "Slide8"] <- "Slide08"
WHNDataset$image_file[WHNDataset$image_file == "Slide9"] <- "Slide09"
#WHNDataset$Block <- factor(WHNDataset$Block, levels = c("0 Control", "1 Visual",  "2 Social", "3 NDRT"))
NoPpts <- n_distinct(WHNDataset$participant)
PPTWHNData <- WHNDataset[!duplicated(WHNDataset$participant), ]
#detach(package:plyr)
WHNSummary <- WHNDataset %>%
group_by(Block) %>%
summarise(WHN = sum(trialResp.corr / NoPpts) ,
WHNPercent = sum((trialResp.corr / NoPpts) /10) * 100,
sdWHN = sd(trialResp.corr),
seWHN = (sd(trialResp.corr))/ sqrt(NoPpts),
meanConf = mean(conf_slider.response, na.rm = T),
sdConf = sd(conf_slider.response),
seConf = (sd(conf_slider.response))/ sqrt(NoPpts),
meanAttention = mean(Attention_slider.response, na.rm = T),
sdAttention = sd(Attention_slider.response, na.rm=T),
seAttention = (sd(Attention_slider.response, na.rm=T))/ sqrt(NoPpts),
trialRespmean = mean(trialResp.rt, na.rm=T),
trialRespSD = sd(trialResp.rt, na.rm=T)
)
write.csv(WHNDataset, "C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 5/data/S5WHN.csv", row.names=FALSE)
ClipSummary <- WHNDataset %>%
group_by(image_file) %>%
summarise(n = n(),
WHN = sum(trialResp.corr),
sdWHN = sd(trialResp.corr))
AttSum <- WHNDataset %>%
group_by(Block) %>%
summarise(n = NoPpts,
mean = mean(Attention_slider.response, na.rm = T),
sd = sd(Attention_slider.response, na.rm = T))
WHNBaseline <- as.numeric(WHNSummary[1,3])
ggplot(data = WHNSummary, aes(x = Block, y = WHN, fill = Block))+
geom_col()+
geom_errorbar(aes(ymin = WHN - sdWHN, ymax = WHN + sdWHN),
width = 0.2,
position = position_dodge(0.9))+
geom_hline(yintercept = WHNBaseline, linetype = "dashed", size = 0.5)+
#geom_hline(yintercept = 8, linetype = "solid", size = 1.0)+
#geom_hline(yintercept = 2, linetype = "dotted", size = 1.0)+
labs(title = "Average Hazard Prediction Score", x = "NDRT Presentation Condition", y = "Average number of correct responses")+
ylim(0,8)+
scale_fill_hue(l = 40)
PlotData <- WHNDataset %>%
select(participant, trialResp.corr, trials_3.thisTrialN, Block) %>%   group_by(participant, Block) %>%
summarise(participant = participant,
score = sum(trialResp.corr),
Block = Block)
ggplot(data = PlotData, aes(x = Block, y = score, fill = Block))+
geom_violin(alpha = 0.8)+
geom_boxplot(alpha = 0, width = 0.2)+
theme_classic()+
ylab("Average Study 4 WHN Score")+
xlab("AR Presentation Condition")
PlotData <- WHNDataset %>%
select(participant, trialResp.corr, trials_3.thisTrialN, Block) %>%   group_by(participant, Block) %>%
summarise(participant = participant,
score = sum(trialResp.corr),
Block = Block)
View(WHNDataset)
