---
title: "Study6WHNAnalysis"
author: "TGoodge"
date: "2024-04-28"
output: html_document
---

#libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(pwr)
library(tidyverse)
library(splitstackshape)
library(stringr)
library(data.table)
library(dplyr)
library(tidyr)
library(gridExtra)
library(lme4)
library(lmerTest)
library(afex)
library(effects)
library(ggplot2)
library(paletteer)
library(ggthemes)
library(report)
library(janitor)
library(stringr)
```
#power
```{r}
pwr.t.test(power= 0.95, sig.level = 0.05, d = 0.814646, type = "one.sample")



# range of correlations
r <- seq(.1,.5,.01)
nr <- length(r)

# power values
p <- seq(.4,.9,.1)
np <- length(p)

# obtain sample sizes
samsize <- array(numeric(nr*np), dim=c(nr,np))
for (i in 1:np){
  for (j in 1:nr){
    result <- pwr.r.test(n = NULL, r = r[j],
    sig.level = .05, power = p[i],
    alternative = "two.sided")
    samsize[j,i] <- ceiling(result$n)
  }
}

# set up graph
xrange <- range(r)
yrange <- round(range(samsize))
colors <- rainbow(length(p))
plot(xrange, yrange, type="n",
  xlab="Correlation Coefficient (r)",
  ylab="Sample Size (n)" )

# add power curves
for (i in 1:np){
  lines(r, samsize[,i], type="l", lwd=2, col=colors[i])
}

# add annotation (grid lines, title, legend)
abline(v=0, h=seq(0,yrange[2],50), lty=2, col="grey89")
abline(h=0, v=seq(xrange[1],xrange[2],.02), lty=2,
   col="grey89")
title("Sample Size Estimation for Correlation Studies\n
  Sig=0.05 (Two-tailed)")
legend("topright", title="Power",
as.character(p),
   fill=colors)
```
#Define palettes
```{r}
library(RColorBrewer)

base_palette <- brewer.pal(n = 12, name = "Paired")
custom_palette <- c(
  base_palette[3], base_palette[4],   # Group 2: 2 similar colors
    base_palette[1], base_palette[2],   # Group 1: 2 similar colors

  "#F45B5B", base_palette[6], "#A50F15",  # Group 3: 3 similar colors
  base_palette[8]                     # Group 4: 1 color
)


S5_palette <- c(base_palette[3],base_palette[1],"#F45B5B", base_palette[8])
S6_palette <- c(base_palette[4], base_palette[2],base_palette[6], "#A50F15")

#scale_fill_manual(values = S6_palette) +


# Print the custom palette to verify
print(custom_palette)
#"#A6CEE3" "#1F78B4" "#B2DF8A" "#33A02C" "#FB9A99" "#E31A1C" "#FDBF6F" "#FF7F00" "#F45B5B"
```
```{r}
dataFolder = "C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 6/Study6Data/WHN/"

file_list <- list.files(path = dataFolder, pattern = "..csv$", all.files = TRUE, full.names = TRUE, recursive = TRUE) 
```

```{r read in raw data}

library(plyr)
RawWHNDataset <- data.frame()
 #loop through all the fills, create a temporary container, remove the first, second and last rows and then add 1 to the trials counter. Then bind it to the dataset
for (file in file_list){
  tempData <- read.csv(file, header = T) 
  RawWHNDataset <- rbind.fill(RawWHNDataset, tempData)
}

library(dplyr)

```
#Sort WHN dataset
```{r}
#Sort dataset for useful columns

SortedWHNDataset <- RawWHNDataset  %>% 
  dplyr::select(participant,date, image_file,Correct,trials_3.thisTrialN, conf_slider.response, conf_slider.rt, Attention_slider.response, trialResp.keys, trialResp.corr, trialResp.rt, preTrial_text.started)

SortedWHNDataset$participant[SortedWHNDataset$participant == "6P01"] <- "SP01"

SortedWHNDataset$Attention_slider.response <- as.numeric(SortedWHNDataset$Attention_slider.response)
SortedWHNDataset$participant <- as.factor(SortedWHNDataset$participant)
SortedWHNDataset$image_file <- as.factor(SortedWHNDataset$image_file)

SortedWHNDataset <- SortedWHNDataset[complete.cases(SortedWHNDataset$trialResp.corr), ]


```

#Read in Counterbalancing
```{r}
#Read in counterbalancing
Counterbalancing <- read.csv("C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 6/Study6CounterbalancingCSV.csv", header = T)

colnames(Counterbalancing) <- c("participant", "First", "Second","Third","Fourth")
```

#Order WHN Dataset
```{r}
OrderWHNDataset <- left_join(SortedWHNDataset, Counterbalancing, by = 'participant') 

OrderWHNDataset$Block 


OrderWHNDataset$Block <-  if_else(OrderWHNDataset$trials_3.thisTrialN >= 30,OrderWHNDataset$Fourth,
                                  if_else(OrderWHNDataset$trials_3.thisTrialN >= 20,OrderWHNDataset$Third,
                                                  if_else(OrderWHNDataset$trials_3.thisTrialN >= 10,OrderWHNDataset$Second, 
                                                          OrderWHNDataset$First)))

OrderWHNDataset$trialResp.rt <-stringr::str_remove_all(OrderWHNDataset$trialResp.rt,"[\\[\\]]")
OrderWHNDataset$trialResp.rt <- as.numeric(OrderWHNDataset$trialResp.rt)



OrderWHNDataset$image_file <- str_sub(OrderWHNDataset$image_file, end = -5)
OrderWHNDataset$Block <- as.factor(OrderWHNDataset$Block)

OrderWHNDataset <- OrderWHNDataset %>% 
  subset(participant != "SP10") %>% 
    subset(participant != "SP12") 


```

```{r}
WHNDataset <- OrderWHNDataset

WHNDataset$Block <- factor(WHNDataset$Block, levels = c("Control", "Visual", "Avatar", "Social"))

```

#Demographics
```{r}
  #Read in the data
  DemogDataRaw <- read.csv("C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 6/Study6Data/Qualtrics/Demogs/TGStudy6Demogs.csv") %>%  
    select(starts_with('Q')) 
```
```{r}
#Change the first row into column headers
DemogDataOrg <- row_to_names(DemogDataRaw, row_number = 1)

DemogDataOrg <- DemogDataOrg %>% 
  subset(DemogDataOrg$`What is your participant ID? 
(First two letters of your first name, the month  number of your birthday and the last two letters of your mothers maiden name - eg TH03ON)` != "DEL-DO12TA")
#Remove consent form columns


```

#Format demographic data

```{r}
library(plyr)
DemogDataOrg <- DemogDataOrg %>% 
  rename(c(`What is your age?` = "Age")) %>% 
rename(c(`Which gender do you identify with?` = "Gender")) %>% 
rename(c(`Do you have a UK driving license?` = "UKLicense")) %>%
rename(c(`Which country did you get your driving license in?` = "CountryLicense")) %>%
rename(c(`How many years driving experience do you have, either from when you passed your driving test or when you started driving regularly? (years / months)` = "YearsExp")) %>%
rename(c(`How many years driving experience do you have in the UK (years, months)` = "UKYearsExp")) %>%
rename(c(`How many years driving experience do you have driving around the West End of Glasgow? (years, months)` = "GlasgowYearsExp")) %>%
rename(c(`Approximately how many hours do you play video games for in an average week?` = "VideoGamesTime")) %>% 
rename(c(`Do you have any history of motion sickness? - Selected Choice` = "MotionSickness")) %>% 
rename(c(`Do you have any history of motion sickness? - Other (Please describe) - Text` = "MotionSicknessText"))


```


```{r}
DemogDataOrg$Age = as.numeric(DemogDataOrg$Age)
DemogDataOrg$VideoGamesTime = as.numeric(DemogDataOrg$VideoGamesTime)

DemogDataOrg$YearsExp = as.numeric(DemogDataOrg$YearsExp)

DemogDataOrg$UKYearsExp = as.numeric(DemogDataOrg$UKYearsExp)
DemogDataOrg$GlasgowYearsExp = as.numeric(DemogDataOrg$GlasgowYearsExp)

DemogDataOrg <- DemogDataOrg[!is.na(DemogDataOrg$Age),]

#table(DemogDataOrg$`How familiar are you with augmented reality (AR) prior to this experiment?`)

#table(DemogDataOrg$`How familiar are you with virtual reality (VR) prior to this experiment?`)


DemogDataOrg <- DemogDataOrg %>% 
  subset(`What is your participant ID? 
(First two letters of your first name, the month  number of your birthday and the last two letters of your mothers maiden name - eg TH03ON)` != "MA05ER") %>% 
    subset(`What is your participant ID? 
(First two letters of your first name, the month  number of your birthday and the last two letters of your mothers maiden name - eg TH03ON)` != "WJ08SH")  %>% 
    subset(`What is your participant ID? 
(First two letters of your first name, the month  number of your birthday and the last two letters of your mothers maiden name - eg TH03ON)` != "IG02SC")  %>% 
    subset(`What is your participant ID? 
(First two letters of your first name, the month  number of your birthday and the last two letters of your mothers maiden name - eg TH03ON)` != "JI02NG") 

```
#Demog Summary
```{r}
DemogSummaryTotal <- DemogDataOrg 

DemogSummaryTotal <- DemogDataOrg %>% 
  summarise(
  AgeMean = mean(Age),
  AgeSD = sd(Age, na.rm = T),
  Male = sum(Gender == 'Male'),
  Female = sum(Gender == "Female"),
  TotalYearsExp = mean(YearsExp),
  TotalYearsExpsd = sd(YearsExp, na.rm = T),
  UKLicense = sum(UKLicense == 'Yes'),
  UKExp = mean(UKYearsExp, na.rm = T),
  UKExpmin = min(UKYearsExp, na.rm = T),
  UKExpmax = max(UKYearsExp, na.rm = T),
  UKEXPsd = sd(UKYearsExp, na.rm = T),
  GlasgowExp = mean(GlasgowYearsExp, na.rm = T),
  GlasgowExpmin = min(GlasgowYearsExp, na.rm = T),
  GlasgowExpmax = max(GlasgowYearsExp, na.rm = T),
  GlasgowExpsd = sd(GlasgowYearsExp, na.rm = T),
  meanVG = mean(VideoGamesTime, na.rm = T),
  meanExp = mean(YearsExp, na.rm = T),
  minExp = min(YearsExp, na.rm = T),
  maxExp = max(YearsExp, na.rm = T),
  sdExp = sd(YearsExp, na.rm = T)

  )   
```
#Extract DBQ Scores

```{r}
DBQ <- DemogDataOrg %>% 
  select(11: 34)

library(dplyr)
DBQ <- DBQ %>% mutate_all(list(~substr(., 1, 1))) 

IDs <- as.data.frame(WHNDataset$participant)

IDs <- IDs[!duplicated(IDs), ]

IDs <- as.data.frame(IDs)

```

```{r}
DBQItems <- cols <- names(DBQ)

DBQ[DBQItems] <- lapply(DBQ[DBQItems], as.numeric)

DBQ$Errors <- 0
DBQ$Lapses <- 0
DBQ$Violations <- 0

DBQ$participant <- IDs

Errors <- DBQ %>% 
  select('participant', starts_with('E')) 
Errors$meanErrors = rowMeans(Errors[2:9])

Errors <- Errors %>% 
  select('participant', 'meanErrors')

Violations <- DBQ %>% 
  select('participant', starts_with('V')) 
Violations$meanViolations = rowMeans(Violations[2:9])

Violations <- Violations %>% 
  select('participant', 'meanViolations')

Lapses <- DBQ %>% 
  select('participant', starts_with('L')) 
Lapses$meanLapses = rowMeans(Lapses[2:9])

Lapses <- Lapses %>% 
  select('participant', 'meanLapses')
```
```{r}
DBQ <- left_join(DBQ, Errors, by = 'participant')

DBQ <- left_join(DBQ, Lapses, by = 'participant')

DBQ <- left_join(DBQ, Violations, by = 'participant')

medianError <- median(DBQ$meanErrors)
medianLapses <- median(DBQ$meanLapses)
medianViolation <- median(DBQ$meanViolations)


DBQ$ErrorGroup <-  ifelse(DBQ$meanErrors >= medianError, "High", "Low")
DBQ$LapseGroup <-  ifelse(DBQ$meanLapses >= medianLapses, "High", "Low")
DBQ$ViolationGroup <-  ifelse(DBQ$meanViolations >= medianViolation, "High", "Low")


```


```{r}
PptDBQ <- DBQ %>% 
  select(25:34)
  
PptDBQ$participant <- PptDBQ$participant$IDs


WHNDataset <- left_join(WHNDataset, PptDBQ, by = 'participant')

WHNDataset$conf_slider.response <- as.numeric(WHNDataset$conf_slider.response)


```



```{r rename slides and factorise the data}
WHNDataset$participant <- as.factor(WHNDataset$participant)

WHNDataset$image_file[WHNDataset$image_file == "Slide1"] <- "Slide01"
WHNDataset$image_file[WHNDataset$image_file == "Slide2"] <- "Slide02"
WHNDataset$image_file[WHNDataset$image_file == "Slide3"] <- "Slide03"
WHNDataset$image_file[WHNDataset$image_file == "Slide4"] <- "Slide04"
WHNDataset$image_file[WHNDataset$image_file == "Slide5"] <- "Slide05"
WHNDataset$image_file[WHNDataset$image_file == "Slide6"] <- "Slide06"
WHNDataset$image_file[WHNDataset$image_file == "Slide7"] <- "Slide07"
WHNDataset$image_file[WHNDataset$image_file == "Slide8"] <- "Slide08"
WHNDataset$image_file[WHNDataset$image_file == "Slide9"] <- "Slide09"

WHNDataset$image_file <- as.factor(WHNDataset$image_file)

#WHNDataset$Block <- factor(WHNDataset$Block, levels = c("0 Control", "1 Visual",  "2 Social", "3 NDRT"))
```

```{r}
NoPpts <- n_distinct(WHNDataset$participant)

PPTWHNData <- WHNDataset[!duplicated(WHNDataset$participant), ]

```
#WHN Summary
```{r summarise the data}

detach(package:plyr)
WHNSummary <- WHNDataset %>% 
  group_by(Block) %>% 
  summarise(WHN = sum(trialResp.corr / NoPpts) ,
            WHNPercent = sum((trialResp.corr / NoPpts) /10) * 100,
            sdWHN = sd(trialResp.corr),
            seWHN = (sd(trialResp.corr))/ sqrt(NoPpts),
            meanConf = mean(conf_slider.response, na.rm = T),
            sdConf = sd(conf_slider.response),
            seConf = (sd(conf_slider.response))/ sqrt(NoPpts),
            meanAttention = mean(Attention_slider.response, na.rm = T),
            sdAttention = sd(Attention_slider.response, na.rm=T),
            seAttention = (sd(Attention_slider.response, na.rm=T))/ sqrt(NoPpts),
            trialRespmean = mean(trialResp.rt, na.rm=T),
            trialRespSD = sd(trialResp.rt, na.rm=T)
            )

CorrConfSummary <- WHNDataset %>% 
  group_by(Block, trialResp.corr) %>% 
  summarise(n = n(),
            conf = mean(conf_slider.response),
                        WHNPercent = sum((trialResp.corr / NoPpts) /10) * 100,
)


WHNPptData <- WHNDataset %>% 
  group_by(participant, Block) %>% 
  summarise(n = n(),
            sumWHN = sum(trialResp.corr),
            meanRT = mean(trialResp.rt),
            sdRT = sd(trialResp.rt),
            meanConf = mean(conf_slider.response),
            sdConf = sd(conf_slider.response),
            meanAtt = mean(Attention_slider.response, na.rm = T),
            sdAtt = sd(Attention_slider.response, na.rm = T),
            ViolationGroup = ViolationGroup,
            LapseGroup = LapseGroup,
            ErrorGroup = ErrorGroup,
            Sort =  paste(participant, Block)
            ) 

WHNPptData <- WHNPptData[!duplicated(WHNPptData$Sort), ]

```

```{r}
write.csv(WHNDataset, "C:/Users/thoma/OneDrive - University of Glasgow/Desktop/Study 6/Study6data/S6WHN.csv", row.names=FALSE)

```
#Clip Summaries
```{r}

ClipSummary <- WHNDataset %>% 
  group_by(image_file) %>% 
  summarise(n = n(),
            WHN = sum(trialResp.corr),
            sdWHN = sd(trialResp.corr))


ClipBlockSummary <- WHNDataset %>% 
  group_by(image_file, Block) %>% 
  summarise(n = n(),
            WHNCorr = sum(trialResp.corr),
            WHNIncorr = n() - sum(trialResp.corr),
            RatioCorr = WHNCorr / n() * 100,
            sdWHN = sd(trialResp.corr))

```
#Clip Plots
```{r}
#library(ggpubfigs)

ggplot(data = ClipSummary, aes(x = image_file, y = WHN, fill = image_file))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90))+
  labs(xlim(0,NoPpts))+
  geom_hline(yintercept = NoPpts)+
    geom_hline(yintercept = NoPpts / 4)

ggplot(data = ClipBlockSummary, aes(x = image_file, y = WHNCorr, fill = Block))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90))+
  labs(xlim(0,NoPpts))+
  geom_hline(yintercept = NoPpts, colour = 'blue')+
  geom_hline(yintercept = NoPpts / 4, colour = 'red', linetype = 'dashed')


```

```{r}
AttSum <- WHNDataset %>% 
  group_by(Block) %>% 
  summarise(n = NoPpts,
            mean = mean(Attention_slider.response, na.rm = T),
            sd = sd(Attention_slider.response, na.rm = T))
```
#WHN Col Plot
```{r}
WHNDataset$Block <- relevel(WHNDataset$Block, ref = "Control")

WHNBaseline <- as.numeric(WHNSummary[1,3])

ggplot(data = WHNSummary, aes(x = Block, y = WHN, fill = Block))+
  geom_col()+
  geom_errorbar(aes(ymin = WHN - sdWHN, ymax = WHN + sdWHN),
                width = 0.2, 
                position = position_dodge(0.9))+
  geom_hline(yintercept = WHNBaseline, linetype = "dashed", size = 0.5)+
  #geom_hline(yintercept = 8, linetype = "solid", size = 1.0)+
  #geom_hline(yintercept = 2, linetype = "dotted", size = 1.0)+
  labs(title = "Average Hazard Prediction Score", x = "NDRT Presentation Condition", y = "Average number of correct responses")+
  ylim(0,10)#+
  #scale_fill_hue(l = 40)


ggplot(data = WHNDataset, aes(x = Block, y = trialResp.corr, fill = Block))+
  stat_summary()
```
#WHN Boxplots
```{r}

WHNDataset$Block <- relevel(WHNDataset$Block, ref = "Control")

PlotData <- WHNDataset %>% 
  select(participant, trialResp.corr, trials_3.thisTrialN, Block) %>%   group_by(participant, Block) %>% 
  summarise(participant = participant,
            score = sum(trialResp.corr),
            Block = Block)

WHNPlot2 <- ggplot(data = PlotData, aes(x = Block, y = score, fill = Block))+
  geom_violin(alpha = 0.5)+
  geom_boxplot(width = 0.1)+
  ylim(0,10)+
scale_fill_manual(values = S6_palette) +
  theme_classic()+
theme(legend.position="none") +theme(text=element_text(size = 20)) +

  theme(axis.text=element_text(size=15))+
  labs(title = "Hazard Prediction Score", x = "NDRT Presentation Condition", y = "Average correct responses")+
    theme(plot.title=element_text(vjust=7))+

  theme(plot.margin =unit(c(1.5,0,0,0),"cm"))



WHNPlot2
```


```{r}
ggplot(data = PlotData, aes(x = Block, y = score, fill = Block))+
  geom_violin(alpha = 0.8)+
  geom_boxplot(alpha = 0, width = 0.2)+
  scale_fill_manual(values = S6_palette) +
    theme_classic()+
  ylab("Average Study 4 WHN Score")+
  xlab("AR Presentation Condition")




```

```{r}
WHNAOV <- glm(family = binomial, data = WHNDataset, formula = trialResp.corr ~ Block)

summary(WHNAOV)

```

#######CONFIDENCE SCORES##############
```{r}
ConfBaseline <- as.numeric(WHNSummary[1,7])


ggplot(data = WHNSummary, aes(x = Block, y = meanConf, fill = Block))+
  geom_col()+
  # geom_errorbar(aes(ymin = meanConf - sdConf/2, ymax = meanConf + sdConf/2),
  #               width = 0.2, 
  #               position = position_dodge(0.9))+
  labs(title = "Average Confidence Score", y = "Mean Confidence Rating", x = "NDRT Presentation Condition")+
  ylim(0,1)+
  scale_fill_hue(l = 40)


ConfPlot2 <- ggplot(data = WHNDataset, aes(x = Block, y = conf_slider.response, fill = Block))+
  geom_violin(alpha = 0.5) + geom_boxplot(width = 0.18)+
  labs(title = "Average Confidence Score", y = "Mean Confidence Rating", x = "", key= FALSE)+
  ylim(0,1.0)+
  scale_fill_manual(values = S6_palette) +
  theme_classic()+
  theme(legend.position="none")+
  theme(text=element_text(size = 15)) +
  theme(axis.text=element_text(size=10))+
  theme(plot.title=element_text(vjust=10))+

  theme(plot.margin =unit(c(1.5,0,0,0),"cm"))


ConfPlot2


ggplot(data = WHNDataset, aes(x = Block, y = conf_slider.response, fill = Block))+
  stat_summary()

```
```{r}
AttBaseline <- as.double(AttSum[1,3])

ggplot(data = AttSum, aes(x = Block, y = mean, fill = Block))+
  geom_col()+
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd),
                width = 0.2, 
                position = position_dodge(0.9))+
  labs(title = "Subjective Attention Rating", y = "Mean Attention Rating", x = "NDRT Presentation Condition")+
  geom_hline(yintercept = AttBaseline, linetype = "dashed", size = 1.0)+
  scale_fill_hue(l = 40)

AttBaseline <- as.double(AttSum[1,3])

AttPlot2 <- ggplot(data = WHNDataset, aes(x = Block, y = Attention_slider.response, fill = Block))+
  geom_violin(alpha = 0.5)+geom_boxplot(width = 0.1)+
 
  labs(title = "Subjective Attention Rating", y = "Mean Attention Rating", x = "NDRT Presentation Condition")+
scale_fill_manual(values = S6_palette) +
  ylim(0,1)+
  theme_classic()+
theme(legend.position="none")+
  theme(text=element_text(size = 15))+
 theme(plot.title=element_text(vjust=10))+
  theme(axis.text=element_text(size=10))+
  theme(plot.margin =unit(c(1.5,0,0,0),"cm"))

  AttPlot2
  
  

ggplot(data = WHNDataset, aes(x = Block, y = Attention_slider.response, fill = Block))+
  stat_summary()
  

```
#FullPlot
```{r group all graphs together}
library(cowplot)

subPlot<- plot_grid(ConfPlot2, AttPlot2, labels = c('b)','c)'),ncol = 1)

subPlot


legend_b <- get_legend(
  WHNPlot2 + 
    guides(color = guide_legend(nrow = 1)) +
   theme(legend.position = "bottom")
)

FullPlot <- plot_grid(WHNPlot2, subPlot, labels = ('a)'))

FinalPlot <- plot_grid(FullPlot, legend_b, ncol = 1, rel_heights = c(1, .1))

FinalPlot

file1 <- tempfile("file1", fileext = ".png")

width = 1920

ggsave(filename = "Robo2FullPlot2.png",
       plot = FinalPlot,
       scale = 3,
       device = png,
       width = 3840,
       units = "px",
       dpi = 700)

```
```{r}
df <- data.frame(WHNPptData$sumWHN)
z_scores <- as.data.frame(sapply(df, function(df) (abs(df-mean(df))/sd(df))))

z_scores$ZScores <- z_scores$WHNPptData


WHNPptData$WHNZScore <- z_scores$ZScores

WHNPptData <- WHNPptData %>% 
  subset(z_scores <= 3)

```

#WHN Stats

```{r}


WHNDataset$Block <- relevel(WHNDataset$Block, ref = "Control")

WHNNullModel0 <- glmer(data = WHNDataset, formula = trialResp.corr ~ 1 + (1|participant) + (1|image_file) , family = binomial, glmerControl( optimizer = "bobyqa"))

WHNModelClip <- glmer(data = WHNDataset, formula = trialResp.corr ~  Block  + (1|image_file) , family = binomial, glmerControl( optimizer = "bobyqa"))

WHNModelBasic <- glmer(data = WHNDataset, formula = trialResp.corr ~  Block + (1 |participant) + (1|image_file) , family = binomial, glmerControl( optimizer = "bobyqa"))

WHNModelPpt <- glmer(data = WHNDataset, formula = trialResp.corr ~  Block + (1 |participant) , family = binomial, glmerControl(optimizer = "bobyqa"))

summary(WHNModelBasic)

 # WHNModel1 <- glmer(data = WHNDataset, formula = trialResp.corr ~  Block + (1 + Block|participant)  , family = binomial, glmerControl( optimizer = "bobyqa"))
 # 
 # summary(WHNModel1)

# 
# WHNModel2 <- glmer(data = WHNDataset, formula = trialResp.corr ~  Block + (1 + participant|image_file), family = binomial, glmerControl( optimizer = "bobyqa"))
# 
# 
# summary(WHNModel2)
# 
# WHNModel3 <- glmer(data = WHNDataset, formula = trialResp.corr ~  Block + (1 + image_file|participant), family = binomial, glmerControl( optimizer = "bobyqa"))
# 
# WHNModel4 <- glmer(data = WHNDataset, formula = trialResp.corr ~  Block  + meanViolations + (1|image_file)  , family = binomial, glmerControl( optimizer = "bobyqa"))
# 
# anova(WHNModel, WHNModelBasic, WHNModel1, WHNModel2, WHNModel3, WHNModel4)
# 
anova(WHNModelClip, WHNModelBasic,WHNModelPpt)
```
```{r}
WHNDatasetRmOUt <- WHNDataset %>% 
  subset(participant != "SP17")

WHNModelBasicRMOUT <- glmer(data = WHNDatasetRmOUt, formula = trialResp.corr ~  Block + (1 |participant) + (1|image_file) , family = binomial, glmerControl( optimizer = "bobyqa"))

summary(WHNModelBasicRMOUT)

```


```{r}
library(lsmeans)

summary(WHNModelBasic)
lsmeans(WHNModelBasic,pairwise~Block)

library(DHARMa)
testDispersion(WHNModelBasic)


simulationOutput <- simulateResiduals(fittedModel = WHNModelBasic, plot = F)
residuals(simulationOutput)
residuals(simulationOutput, quantileFunction = qnorm, outlierValues = c(-7,7))
plot(simulationOutput)


plotResiduals(simulationOutput, form = WHNDataset$Block)
# plotQQunif(simulationOutput) # left plot in plot.DHARMa()
# plotResiduals(simulationOutput) # right plot in plot.DHARMa()

simulationOutput <- simulateResiduals(fittedModel = WHNModelBasic, refit = F)


testDispersion(simulationOutput)
plot(simulationOutput)
testZeroInflation(simulationOutput)

countOnes <- function(x) sum(x == 1)  # testing for number of 1s
testGeneric(simulationOutput, summary = countOnes, alternative = "greater") # 1-inflation
```


```{r}
library(effects)

ef <- as.data.frame(effect("Block", WHNModelBasic))
head(ef)

library(report)
WHNResults <- report(WHNModelBasic, CI = 95)

summary(WHNResults)


```


#WHN RT
```{r}


WHNRTModelBasic <- lmer(data = WHNDataset, formula = trialResp.rt ~  Block + (1 |participant) + (1|image_file))
summary(WHNRTModelBasic)

WHNPlotRT <- ggplot(data = WHNDataset, aes(x = Block, y = trialResp.rt, fill = Block))+
  geom_violin(alpha = 0.5)+
  geom_boxplot(width = 0.1)+
  #ylim(0,10)+
scale_fill_manual(values = S6_palette) +
  theme_classic()+
theme(legend.position="none") +theme(text=element_text(size = 20)) +

  theme(axis.text=element_text(size=15))+
  labs(title = "Hazard Prediction Score", x = "NDRT Presentation Condition", y = "Average time to make choice")+
    theme(plot.title=element_text(vjust=7))+

  theme(plot.margin =unit(c(1.5,0,0,0),"cm"))



WHNPlotRT

```


```{r}
WHNPptSummary <- WHNPptData %>% 
  group_by(Block) %>% 
  summarise(n = n(),
            meanWHN = mean(sumWHN),
            sdWHN = sd(sumWHN)
            )

```


```{r}
WHNPptData$Block <- relevel(WHNPptData$Block, ref = "Visual")

```


```{r}
# library(tidyverse)
# library(ggpubr)
# library(rstatix)
# #
# WHNPptData %>% 
#   group_by(Block) %>% 
#   get_summary_stats(sumWHN, type = "mean_sd")
# 
# bxp <- ggboxplot(WHNPptData, x = "Block", y = "sumWHN", add = "point")
# bxp
# 
# WHNPptData %>% 
#   group_by(Block) %>% 
#  identify_outliers(sumWHN)
# 
# WHNPptData %>% 
#   group_by(Block) %>% 
#   shapiro_test(sumWHN)
# 
# ggqqplot(WHNPptData, "sumWHN", facet.by = "Block")
# 
# 
# res.aov <- anova_test(data = WHNPptData, dv = sumWHN, wid = participant, within = Block)
# get_anova_table(res.aov)
# 
# pwc <- WHNPptData %>%
#   pairwise_t_test(
#     sumWHN ~ Block, paired = TRUE,
#     p.adjust.method = "bonferroni"
#     )
# pwc
```


#Confidence Stats
```{r}

WHNDataset$Block <- relevel(WHNDataset$Block, ref = "Social")

ConfNullModel <- lmer(data = WHNDataset, formula = conf_slider.response ~  (1|participant) + (1|image_file))

ConfModelPpt <-  lmer(data = WHNDataset, formula = conf_slider.response ~ Block + (1|participant) )

ConfModelClip <-  lmer(data = WHNDataset, formula = conf_slider.response ~ Block +(1|image_file))

ConfModel = lmer(data = WHNDataset, formula = conf_slider.response ~ Block + (1|participant) + (1|image_file))
summary(ConfModel)

#ConfModel2 = lmer(data = WHNDataset, formula = conf_slider.response ~ Block + (1|participant) + (1 + image_file|participant))
 # 
 # ConfModel3 = glmer(data = WHNDataset, formula = conf_slider.response ~ Block + (1 + Block|participant) + (1 + Block|image_file),family = binomial, glmerControl(optimizer = "bobyqa"))


anova(ConfModel, ConfModelPpt, ConfModelClip, ConfNullModel)

summary(ConfModel)

```
#Confidence expand Corr
```{r}
WHNCorr <- WHNDataset %>% 
  subset(trialResp.corr == 1)

WHNCorr$Block <- relevel(WHNCorr$Block, ref = "Avatar")


CorrConfModel = glmer(data = WHNCorr, formula = conf_slider.response ~ Block + (1|participant) + (1|image_file),  family = binomial, glmerControl(optimizer = "bobyqa"))
summary(CorrConfModel)


```

#Confidence expand Incorrect
```{r}
WHNIncorr <- WHNDataset %>% 
  subset(trialResp.corr == 0)

WHNIncorr$Block <- relevel(WHNIncorr$Block, ref = "Control")


IncorConfModel = glmer(data = WHNIncorr, formula = conf_slider.response ~ Block + (1|participant) + (1|image_file),  family = binomial, glmerControl(optimizer = "bobyqa"))
summary(IncorConfModel)

```

```{r Conf GLMER Summary}

Confresults <- report(ConfModel, CI = 95)

summary(ConfModel)

fixef(ConfModel)

print(Confresults)

efconf <- as.data.frame(effect("Block", ConfModel))
head(efconf)

```
#Attention stats
```{r}
AttentionDataset <- WHNDataset %>% 
  subset(!is.na(Attention_slider.response))


AttAOV <- aov(data = AttentionDataset,formula =  Attention_slider.response ~ Block)
summary(AttAOV)
TukeyHSD(AttAOV)
```

```{r}
AttentionSummary <- AttentionDataset %>% 
  group_by(Block) %>% 
summarise(n = n(),
          mean = mean(Attention_slider.response),
          sd = sd(Attention_slider.response))


```

```{r}

ggplot(AttentionDataset, aes(x=Attention_slider.response)) +
    geom_histogram(binwidth=0.1, colour="black", fill="white")

library(rstatix)
AttentionDataset %>% 
  group_by(Block) %>% 
  identify_outliers(Attention_slider.response)

AttentionDataset %>% 
  group_by(Block) %>% 
  shapiro_test(Attention_slider.response)

library(ggpubr)

ggqqplot(AttentionDataset, "Attention_slider.response", facet.by = "Block")
```

```{r}

AttentionDataset$Block <- relevel(AttentionDataset$Block, ref = "Control")

Att.aov <- anova_test(data = AttentionDataset, dv = Attention_slider.response, wid = participant, within = Block)

get_anova_table(Att.aov)

Attpwc <- AttentionDataset %>% 
  pairwise_t_test(Attention_slider.response ~ Block, paired = TRUE,
                  p.adjust.method = "bonferroni")

Attpwc <- Attpwc %>%  add_xy_position(x = "Block")

Attpwc


bxp <- ggboxplot(AttentionDataset, x = "Block", y = "Attention_slider.response", add = "point")

bxp + 
  #stat_pvalue_manual(pwc) +
  labs(
    subtitle = get_test_label(Att.aov, detailed = TRUE),
    caption = get_pwc_label(Attpwc)
  )


```

#Attention Glmers
```{r}

AttentionDataset$Block <- relevel(AttentionDataset$Block, ref = "Control - 2")

AttModel1 <- lmer(data = AttentionDataset, formula = Attention_slider.response ~ Block + (1|participant))

# AttModel2 <- glmer(family = binomial, data = AttentionDataset, formula = Attention_slider.response ~ Block + (1|participant) + (1|trials_3.thisTrialN), glmerControl(optimizer = "bobyqa"))
# 
# AttModel3 <- glmer(family = binomial, data = AttentionDataset, formula = Attention_slider.response ~ Block + conf_slider.response + (1|participant) , glmerControl(optimizer = "bobyqa"))

summary(AttModel1)


#anova(AttModel1, AttModel2, AttModel3)



```
#######DBQ Comparisons###########

```{r}
ErrorWHNaov <- aov(data = WHNDataset, formula = trialResp.corr ~ Block * ErrorGroup)
summary(ErrorWHNaov)

LapseWHNaov <- aov(data = WHNDataset, formula = trialResp.corr ~ Block * LapseGroup)
summary(LapseWHNaov)

ViolationWHNaov <- aov(data = WHNDataset, formula = trialResp.corr ~ Block * ViolationGroup)
summary(ViolationWHNaov)

```



```{r}
Erroraov <- aov(data = WHNDataset, formula = trialResp.rt ~ Block * ErrorGroup)
summary(Erroraov)

Lapseaov <- aov(data = WHNDataset, formula = trialResp.rt ~ Block * LapseGroup)
summary(Lapseaov)

#TukeyHSD(Lapseaov, which = "LapseGroup")


Violationaov <- aov(data = WHNDataset, formula = trialResp.rt ~ Block * ViolationGroup)
summary(Violationaov)

```
```{r}
ErrorConfaov <- aov(data = WHNDataset, formula = conf_slider.response ~ Block * ErrorGroup)
summary(ErrorConfaov)

#TukeyHSD(ErrorConfaov)


LapseConfaov <- aov(data = WHNDataset, formula = conf_slider.response ~ Block * LapseGroup)
summary(LapseConfaov)

#TukeyHSD(LapseConfaov, which = "LapseGroup")

ViolationConfaov <- aov(data = WHNDataset, formula = conf_slider.response ~ Block * ViolationGroup)
summary(ViolationConfaov)

TukeyHSD(ViolationConfaov)

```

```{r}
ErrorAttaov <- aov(data = WHNDataset, formula = Attention_slider.response ~ Block * ErrorGroup)
summary(ErrorAttaov)

LapseAttaov <- aov(data = WHNDataset, formula = Attention_slider.response ~ Block * LapseGroup)
summary(LapseAttaov)

TukeyHSD(LapseAttaov, which = "LapseGroup")

ViolationAttaov <- aov(data = WHNDataset, formula = Attention_slider.response ~ Block * ViolationGroup)
summary(ViolationAttaov)

TukeyHSD(ViolationAttaov, which = "ViolationGroup")


```

